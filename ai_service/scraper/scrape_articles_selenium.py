import json
import time
import sys
import os
import requests
from datetime import datetime
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import logging
from bs4 import BeautifulSoup

# ğŸ”¹ Laravel Backend API URL - Update as needed
BACKEND_API_URL = "http://localhost:8000/api/articles/import"

def setup_driver():
    """Setup and return a configured Chrome WebDriver instance"""
    chrome_options = Options()
    chrome_options.add_argument("--headless")  # Run in headless mode
    chrome_options.add_argument("--disable-gpu")
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument("--window-size=1920,1080")
    chrome_options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36")
    
    service = Service(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service, options=chrome_options)
    
    return driver

def extract_content(driver, url, title="Unknown title"):
    """
    TrÃ­ch xuáº¥t ná»™i dung cÃ³ cáº¥u trÃºc tá»« URL bÃ i viáº¿t, táº­p trung vÃ o tiÃªu Ä‘á» vÃ  tháº» p
    
    Args:
        driver (WebDriver): Driver Selenium
        url (str): URL cá»§a bÃ i viáº¿t
        title (str): TiÃªu Ä‘á» bÃ i viáº¿t
        
    Returns:
        str: Ná»™i dung bÃ i viáº¿t
    """
    try:
        print(f"ğŸ“„ Äang truy cáº­p URL: {url}")
        driver.get(url)
        
        # Chá» ná»™i dung táº£i xong
        WebDriverWait(driver, 15).until(
            EC.presence_of_element_located((By.TAG_NAME, "body"))
        )
        
        # Láº¥y ná»™i dung trang
        page_content = driver.page_source
        
        # Sá»­ dá»¥ng BeautifulSoup Ä‘á»ƒ phÃ¢n tÃ­ch HTML
        soup = BeautifulSoup(page_content, "html.parser")
        
        # TrÃ­ch xuáº¥t tiÃªu Ä‘á» tá»« tháº» h1 hoáº·c cÃ¡c tháº» tiÃªu Ä‘á» phá»• biáº¿n
        extracted_title = ""
        heading_tags = soup.find_all(['h1', 'h2'])
        for tag in heading_tags:
            if tag.text.strip() and len(tag.text.strip()) > 10:
                extracted_title = tag.text.strip()
                break
        
        # TrÃ­ch xuáº¥t ná»™i dung tá»« cÃ¡c tháº» p (paragraph)
        content_paragraphs = []
        paragraphs = soup.find_all('p')
        
        for p in paragraphs:
            # Lá»c cÃ¡c Ä‘oáº¡n vÄƒn cÃ³ nghÄ©a (loáº¡i bá» cÃ¡c Ä‘oáº¡n quÃ¡ ngáº¯n hoáº·c lÃ  thÃ´ng tin phá»¥)
            text = p.text.strip()
            if text and len(text) > 20:  # Chá»‰ láº¥y Ä‘oáº¡n vÄƒn dÃ i hÆ¡n 20 kÃ½ tá»±
                content_paragraphs.append(text)
        
        # Káº¿t há»£p ná»™i dung thÃ nh má»™t chuá»—i vÄƒn báº£n
        full_content = ""
        
        # ThÃªm tiÃªu Ä‘á» vÃ o ná»™i dung (náº¿u tÃ¬m tháº¥y)
        if extracted_title:
            full_content += extracted_title + "\n\n"
        
        # ThÃªm ná»™i dung cá»§a cÃ¡c Ä‘oáº¡n vÄƒn
        if content_paragraphs:
            full_content += "\n\n".join(content_paragraphs)
        else:
            # Náº¿u khÃ´ng tÃ¬m tháº¥y tháº» p cÃ³ ná»™i dung, thá»­ phÆ°Æ¡ng phÃ¡p trÃ­ch xuáº¥t vÄƒn báº£n thÃ´
            logging.warning(f"KhÃ´ng tÃ¬m tháº¥y ná»™i dung tá»« tháº» p cho URL: {url}, dÃ¹ng phÆ°Æ¡ng phÃ¡p dá»± phÃ²ng")
            
            # Loáº¡i bá» cÃ¡c pháº§n tá»­ script, style, nav, header, footer, ads
            for element in soup(['script', 'style', 'nav', 'header', 'footer', 'iframe', 'aside']):
                element.extract()
            
            # Láº¥y vÄƒn báº£n
            text = soup.get_text()
            
            # Xá»­ lÃ½ vÄƒn báº£n
            lines = (line.strip() for line in text.splitlines())
            chunks = (phrase.strip() for line in lines for phrase in line.split("  "))
            full_content = "\n".join(chunk for chunk in chunks if chunk)
        
        word_count = len(full_content.split())
        print(f"âœ… TrÃ­ch xuáº¥t thÃ nh cÃ´ng ná»™i dung ({word_count} tá»«) tá»«: {title}")
        
        return full_content
    
    except Exception as e:
        logging.error(f"Lá»—i khi trÃ­ch xuáº¥t ná»™i dung tá»« {url}: {str(e)}")
        print(f"âš ï¸ KhÃ´ng thá»ƒ trÃ­ch xuáº¥t ná»™i dung tá»«: {title}")
        return ""

def filter_article(url):
    """
    Kiá»ƒm tra xem URL cÃ³ phÃ¹ há»£p cho viá»‡c trÃ­ch xuáº¥t ná»™i dung hay khÃ´ng
    
    Args:
        url (str): URL cá»§a bÃ i viáº¿t
        
    Returns:
        bool: True náº¿u URL phÃ¹ há»£p, False náº¿u cáº§n loáº¡i bá»
    """
    # Loáº¡i bá» cÃ¡c URL tá»« vtv.vn/video/ vÃ¬ Ä‘Ã¢y lÃ  ná»™i dung video
    if "vtv.vn/video/" in url:
        logging.warning(f"Bá» qua URL video khÃ´ng phÃ¹ há»£p: {url}")
        return False
    
    return True

def enrich_article(driver, article):
    """
    LÃ m phong phÃº thÃªm dá»¯ liá»‡u bÃ i viáº¿t báº±ng cÃ¡ch trÃ­ch xuáº¥t ná»™i dung Ä‘áº§y Ä‘á»§ tá»« URL
    
    Args:
        driver (WebDriver): Driver Selenium
        article (dict): ThÃ´ng tin bÃ i viáº¿t
        
    Returns:
        dict: BÃ i viáº¿t Ä‘Ã£ Ä‘Æ°á»£c lÃ m phong phÃº thÃªm
    """
    url = article.get("source_url")
    # Bá» qua náº¿u khÃ´ng cÃ³ URL
    if not url:
        logging.warning(f"KhÃ´ng cÃ³ URL cho bÃ i viáº¿t: {article.get('title', 'Unknown title')}")
        return article
    
    # Kiá»ƒm tra URL cÃ³ phÃ¹ há»£p hay khÃ´ng
    if not filter_article(url):
        logging.info(f"Bá» qua URL khÃ´ng phÃ¹ há»£p: {url}")
        return None
    
    try:
        full_content = extract_content(driver, url, article.get("title", "Unknown title"))
        # Cáº­p nháº­t ná»™i dung
        article["content"] = full_content
        
        # Xá»­ lÃ½ meta_data (cÃ³ thá»ƒ lÃ  chuá»—i JSON hoáº·c dict)
        if isinstance(article.get("meta_data"), str):
            try:
                meta_data = json.loads(article["meta_data"])
                meta_data["extracted_at"] = datetime.now().isoformat()
                meta_data["word_count"] = len(full_content.split())
                article["meta_data"] = json.dumps(meta_data)
            except json.JSONDecodeError:
                # Náº¿u khÃ´ng pháº£i JSON há»£p lá»‡, táº¡o má»›i
                article["meta_data"] = json.dumps({
                    "extracted_at": datetime.now().isoformat(),
                    "word_count": len(full_content.split())
                })
        else:
            # Xá»­ lÃ½ trÆ°á»ng há»£p lÃ  dict
            if not article.get("meta_data"):
                article["meta_data"] = {}
            article["meta_data"]["extracted_at"] = datetime.now().isoformat()
            article["meta_data"]["word_count"] = len(full_content.split())
            
        return article
    except Exception as e:
        logging.error(f"Lá»—i khi trÃ­ch xuáº¥t ná»™i dung cho {url}: {str(e)}")
        return article

def send_to_backend(articles):
    """
    Send articles to the Laravel backend API
    
    Args:
        articles (list): List of article data to send
        
    Returns:
        bool: Success status
    """
    try:
        payload = {"articles": articles}
        headers = {"Content-Type": "application/json"}
        
        response = requests.post(BACKEND_API_URL, json=payload, headers=headers)
        
        if response.status_code in (200, 201):
            result = response.json()
            print(f"âœ… ÄÃ£ gá»­i thÃ nh cÃ´ng {result.get('message', '')}")
            if 'errors' in result and result['errors']:
                print(f"âš ï¸ CÃ³ {len(result['errors'])} lá»—i trong quÃ¡ trÃ¬nh import:")
                for error in result['errors']:
                    print(f"  - {error}")
            return True
        else:
            print(f"âŒ Lá»—i khi gá»­i bÃ i viáº¿t tá»›i backend: {response.status_code} - {response.text}")
            return False
    except Exception as e:
        print(f"âŒ Lá»—i káº¿t ná»‘i tá»›i backend: {str(e)}")
        return False

def main():
    """Main function to orchestrate the content enrichment process"""
    # Get input file from command line or use latest scraped file
    if len(sys.argv) > 1:
        input_file = sys.argv[1]
    else:
        # Find latest scraped_articles file
        files = [f for f in os.listdir('.') if f.startswith('scraped_articles_') and f.endswith('.json')]
        if not files:
            print("âŒ KhÃ´ng tÃ¬m tháº¥y file bÃ i viáº¿t. HÃ£y cháº¡y google_news_serpapi.py trÆ°á»›c!")
            return
        input_file = max(files)  # Get most recent file
    
    print(f"ğŸ“‚ Äang Ä‘á»c dá»¯ liá»‡u tá»« file: {input_file}")
    
    # Load articles from file
    try:
        with open(input_file, "r", encoding="utf-8") as f:
            articles = json.load(f)
    except Exception as e:
        print(f"âŒ Lá»—i khi Ä‘á»c file {input_file}: {str(e)}")
        return
    
    if not articles:
        print("âŒ KhÃ´ng cÃ³ bÃ i viáº¿t nÃ o trong file!")
        return
    
    print(f"ğŸ” ÄÃ£ tÃ¬m tháº¥y {len(articles)} bÃ i viáº¿t Ä‘á»ƒ xá»­ lÃ½")
    
    # Setup WebDriver
    driver = setup_driver()
    
    try:
        # Process each article to get full content
        enriched_articles = []
        
        for i, article in enumerate(articles):
            print(f"[{i+1}/{len(articles)}] Äang xá»­ lÃ½: {article['title']}")
            enriched = enrich_article(driver, article)
            if enriched:
                enriched_articles.append(enriched)
            
            # Add delay between requests to avoid overloading servers
            if i < len(articles) - 1:
                time.sleep(2)
        
        # Save enriched articles to file
        output_file = f"enriched_articles_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(output_file, "w", encoding="utf-8") as f:
            json.dump(enriched_articles, f, ensure_ascii=False, indent=4)
        
        print(f"âœ… ÄÃ£ lÆ°u {len(enriched_articles)} bÃ i viáº¿t Ä‘Ã£ lÃ m giÃ u vÃ o {output_file}")
        
        # Ask to send to backend
        if enriched_articles:
            send_option = input("Báº¡n cÃ³ muá»‘n gá»­i bÃ i viáº¿t tá»›i backend? (y/n): ").lower()
            if send_option == 'y':
                send_to_backend(enriched_articles)
    
    finally:
        # Clean up
        driver.quit()
        print("ğŸ”š ÄÃ£ hoÃ n thÃ nh quÃ¡ trÃ¬nh trÃ­ch xuáº¥t ná»™i dung")

if __name__ == "__main__":
    main()
